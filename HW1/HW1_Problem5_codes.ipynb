{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$\\color{red}{\\text{Machine Learning}}$$\n",
    "\n",
    "$$\\color{orange}{\\text{Naive Bayes Classifier}}$$\n",
    "\n",
    "$$\\color{lime}{\\text{Alireza Javid - 810198375}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{deepskyblue}{\\text{Import Libraries}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{deepskyblue}{\\text{Preprocessing}}$\n",
    "In this part we take a close look at our dataset. As we can see some of our data is missing and we have 'x' for value of them. We can drop them or decide to fill them with mean or mode of the data. We decide to drop this rows and avoid adding unnecessary bias to our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186</td>\n",
       "      <td>3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18</td>\n",
       "      <td>195</td>\n",
       "      <td>3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193</td>\n",
       "      <td>3450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g\n",
       "0  Adelie             39.1            18.7               181        3750\n",
       "1  Adelie             39.5            17.4               186        3800\n",
       "2  Adelie             40.3              18               195        3250\n",
       "3  Adelie                x               x                 x           x\n",
       "4  Adelie             36.7            19.3               193        3450"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data\\penguins.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"body_mass_g\"] == 'x'].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{deepskyblue}{\\text{Naive Bayes from Scratch}}$\n",
    "Gaussian Naive Bayes is a powerful and efficient classification algorithm applicable to diverse tasks, that involves calculating prior probabilities for each class, fitting Gaussian distributions for each feature and class, calculating the likelihood of new data points belonging to each class, and selecting the class with the highest posterior probability as the final prediction, while adjusting algorithmic parameters to optimize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = {}\n",
    "for col in df.species.unique():\n",
    "    prior[col] = df.groupby(\"species\").count()[\"body_mass_g\"][col] / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To derive suitable normal distribution we need to calculate the mean and variance of each feature based on their class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_norm_map(df, colname, by='species'):\n",
    "    norm_map = {}\n",
    "    grouped = df.groupby(by)[colname]\n",
    "    for species, group in grouped:\n",
    "        mean = group.astype(float).mean()\n",
    "        std = group.astype(float).std()\n",
    "        norm_map[species] = norm(mean, std)\n",
    "    return norm_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {}\n",
    "maps['body_mass_g'] = make_norm_map(df, 'body_mass_g')\n",
    "maps['flipper_length_mm'] = make_norm_map(df, 'flipper_length_mm')\n",
    "maps['culmen_depth_mm'] = make_norm_map(df, 'culmen_depth_mm')\n",
    "maps['culmen_length_mm'] = make_norm_map(df, 'culmen_length_mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to compare posterior probabilities and make the decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_decision(prior, data_seq, norm_maps, labels):\n",
    "    posterior = {}\n",
    "    for lable in labels:\n",
    "        posterior[lable] = prior[lable]\n",
    "        for c in maps.keys():\n",
    "            posterior[lable] = posterior[lable] * norm_maps[c][lable].pdf(float(data_seq[c]))\n",
    "    return max(posterior, key=lambda k: posterior.get(k))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Classification'] = np.nan\n",
    "for i, row in df.iterrows():\n",
    "    data_seq = row[maps.keys()]\n",
    "    df.loc[i, 'Classification'] = naive_decision(prior, data_seq, maps, df.species.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9703264094955489\n"
     ]
    }
   ],
   "source": [
    "accuracy = df[df['Classification'] == df['species']].shape[0] / df.shape[0]\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = {}\n",
    "true_negatives = {}\n",
    "false_positives = {}\n",
    "false_negatives = {}\n",
    "\n",
    "for lable in df.species.unique():\n",
    "    true_positives[lable] = df[(df['Classification'] == lable) & (df['species'] == lable)].shape[0]\n",
    "    true_negatives[lable] = df[(df['Classification'] != lable) & (df['species'] != lable)].shape[0]\n",
    "    false_positives[lable] = df[(df['Classification'] == lable) & (df['species'] != lable)].shape[0]\n",
    "    false_negatives[lable] = df[(df['Classification'] != lable) & (df['species'] == lable)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix for Adelie\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 182                   5\n",
      "Actual Positive                   5                 145\n",
      "Precision:  0.9666666666666667\n",
      "Recall:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(np.array([[true_negatives['Adelie'], false_positives['Adelie']]\n",
    "                                , [false_negatives['Adelie'], true_positives['Adelie']]]),\n",
    "                                columns=['Predicted Negative', 'Predicted Positive'], index=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "print(\" Confusion Matrix for Adelie\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "precision = true_positives['Adelie'] / (true_positives['Adelie'] + false_positives['Adelie'])\n",
    "recall = true_positives['Adelie'] / (true_positives['Adelie'] + false_negatives['Adelie'])\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix for Chinstrap\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 265                   5\n",
      "Actual Positive                   5                  62\n",
      "Precision:  0.9253731343283582\n",
      "Recall:  0.9253731343283582\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(np.array([[true_negatives['Chinstrap'], false_positives['Chinstrap']]\n",
    "                                , [false_negatives['Chinstrap'], true_positives['Chinstrap']]]),\n",
    "                                columns=['Predicted Negative', 'Predicted Positive'], index=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "print(\" Confusion Matrix for Chinstrap\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "precision = true_positives['Chinstrap'] / (true_positives['Chinstrap'] + false_positives['Chinstrap'])\n",
    "recall = true_positives['Chinstrap'] / (true_positives['Chinstrap'] + false_negatives['Chinstrap'])\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix for Gentoo\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 217                   0\n",
      "Actual Positive                   0                 120\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(np.array([[true_negatives['Gentoo'], false_positives['Gentoo']]\n",
    "                                , [false_negatives['Gentoo'], true_positives['Gentoo']]]),\n",
    "                                columns=['Predicted Negative', 'Predicted Positive'], index=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "print(\" Confusion Matrix for Gentoo\")\n",
    "print(confusion_matrix)\n",
    "\n",
    "precision = true_positives['Gentoo'] / (true_positives['Gentoo'] + false_positives['Gentoo'])\n",
    "recall = true_positives['Gentoo'] / (true_positives['Gentoo'] + false_negatives['Gentoo'])\n",
    "\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\color{deepskyblue}{\\text{Naive Bayes with Sklearn}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[145   5   0]\n",
      " [  5  62   0]\n",
      " [  0   0 120]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       0.97      0.97      0.97       150\n",
      "   Chinstrap       0.93      0.93      0.93        67\n",
      "      Gentoo       1.00      1.00      1.00       120\n",
      "\n",
      "    accuracy                           0.97       337\n",
      "   macro avg       0.96      0.96      0.96       337\n",
      "weighted avg       0.97      0.97      0.97       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "df = df.drop([\"Classification\"],axis=1)\n",
    "X = df.drop([\"species\"],axis=1)\n",
    "y = df[\"species\"]\n",
    "naive_bayes_model = GaussianNB()\n",
    "y_pred = naive_bayes_model.fit(X, y).predict(X)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(y, y_pred, target_names=df.species.unique())\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix for Adelie\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 145                   5\n",
      "Actual Positive                   5                 145\n",
      " Confusion Matrix for Chinstrap\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                  62                   5\n",
      "Actual Positive                   5                  62\n",
      " Confusion Matrix for Gentoo\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 120                   0\n",
      "Actual Positive                   0                 120\n"
     ]
    }
   ],
   "source": [
    "for i, species in enumerate(df.species.unique()):\n",
    "    tp = cm[i][i]\n",
    "    tn = sum([sum(row) - row[i] for j, row in enumerate(cm) if j != i])\n",
    "    fp = sum(cm[:, i]) - tp\n",
    "    fn = sum(cm[i]) - tp\n",
    "    confusion_matrix = pd.DataFrame(np.array([[tp, fp]\n",
    "                                , [fn, tp]]),\n",
    "                                columns=['Predicted Negative', 'Predicted Positive'], index=['Actual Negative', 'Actual Positive'])\n",
    "\n",
    "    print(\" Confusion Matrix for \" + species)\n",
    "    print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a0a51feb3fe677077fd56f2294d600116797ec6b36f034b72c6e60af1880e8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
